{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8e260b-5153-44d3-aab6-2c41432da74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/08 17:08:43 WARN Utils: Your hostname, Josephs-MacBook-Air-67.local resolves to a loopback address: 127.0.0.1; using 10.18.167.2 instead (on interface en0)\n",
      "24/12/08 17:08:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/08 17:08:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+--------+-----------+--------------------+--------------------+------------------+--------------------+\n",
      "| ticket_id|customer_id|issue_category|priority|     status|       creation_date|     resolution_date|satisfaction_score|         description|\n",
      "+----------+-----------+--------------+--------+-----------+--------------------+--------------------+------------------+--------------------+\n",
      "|TICK-00000|   CUST-079|       Billing|    High|   Resolved|2024-11-19 14:47:...|2024-11-21 14:47:...|                 2|Customer reported...|\n",
      "|TICK-00001|   CUST-040|      Security|    High|In Progress|2024-11-24 03:45:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00002|   CUST-068|  Login Issues|Critical|   Resolved|2024-11-22 03:47:...|2024-11-24 11:47:...|                 2|Customer reported...|\n",
      "|TICK-00003|   CUST-024|   Performance|  Medium|  Escalated|2024-11-12 00:11:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00004|   CUST-004|       Storage|    High|  Escalated|2024-11-14 18:48:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00005|   CUST-063|    Networking|Critical|   Resolved|2024-11-25 19:00:...|2024-11-26 17:00:...|                 4|Customer reported...|\n",
      "|TICK-00006|   CUST-033|   Performance|  Medium|In Progress|2024-11-27 14:52:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00007|   CUST-030|    Networking|     Low|        New|2024-12-05 22:10:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00008|   CUST-100|      Security|     Low|In Progress|2024-11-15 04:01:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00009|   CUST-078|   Performance|Critical|        New|2024-11-14 21:30:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00010|   CUST-092|   Performance|     Low|In Progress|2024-11-23 08:46:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00011|   CUST-041|  Login Issues|     Low|  Escalated|2024-11-30 20:27:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00012|   CUST-042|       Billing|     Low|        New|2024-11-20 11:05:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00013|   CUST-074|       Storage|  Medium|     Closed|2024-11-13 06:29:...|2024-11-15 18:29:...|                 1|Customer reported...|\n",
      "|TICK-00014|   CUST-067|       Storage|  Medium|        New|2024-11-18 09:07:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00015|   CUST-099|  Login Issues|    High|In Progress|2024-11-19 03:18:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00016|   CUST-004|   Performance|Critical|     Closed|2024-12-04 18:18:...|2024-12-05 09:18:...|                 2|Customer reported...|\n",
      "|TICK-00017|   CUST-098|    Networking|  Medium|        New|2024-11-10 22:00:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00018|   CUST-019|      Database|  Medium|        New|2024-11-30 17:07:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00019|   CUST-011|      Database|  Medium|     Closed|2024-12-04 17:06:...|2024-12-06 18:06:...|                 3|Customer reported...|\n",
      "+----------+-----------+--------------+--------+-----------+--------------------+--------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "from generate_data import *\n",
    "\n",
    "# Initialize Spark\n",
    "spark = create_spark_session()\n",
    "\n",
    "# Generate and save data\n",
    "schema = define_schema()\n",
    "data = generate_sample_data(1000)\n",
    "df = save_data(spark, data, schema, \"../data/raw/support_tickets\")\n",
    "\n",
    "# Display sample data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d75a3e-726e-4ed6-a4bb-f6e5afe8bf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of generated tickets:\n",
      "+----------+-----------+---------------+--------+-----------+--------------------+--------------------+------------------+--------------------+\n",
      "| ticket_id|customer_id| issue_category|priority|     status|       creation_date|     resolution_date|satisfaction_score|         description|\n",
      "+----------+-----------+---------------+--------+-----------+--------------------+--------------------+------------------+--------------------+\n",
      "|TICK-00000|   CUST-010|       Security|  Medium|   Resolved|2024-12-06 15:38:...|2024-12-08 18:38:...|                 3|Customer reported...|\n",
      "|TICK-00001|   CUST-097|    Performance|    High|  Escalated|2024-11-11 22:16:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00002|   CUST-068|API Integration|  Medium|        New|2024-11-19 08:35:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00003|   CUST-088|   Login Issues|     Low|In Progress|2024-12-02 14:55:...|                NULL|              NULL|Customer reported...|\n",
      "|TICK-00004|   CUST-030|        Billing|     Low|   Resolved|2024-11-11 21:45:...|2024-11-12 13:45:...|                 1|Customer reported...|\n",
      "+----------+-----------+---------------+--------+-----------+--------------------+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Dataset Statistics:\n",
      "Total Tickets: 1000\n",
      "\n",
      "Distribution by Category:\n",
      "+---------------+-----+\n",
      "| issue_category|count|\n",
      "+---------------+-----+\n",
      "|       Security|  117|\n",
      "|API Integration|  144|\n",
      "|   Login Issues|  104|\n",
      "|     Networking|  126|\n",
      "|        Storage|  128|\n",
      "|    Performance|  127|\n",
      "|       Database|  132|\n",
      "|        Billing|  122|\n",
      "+---------------+-----+\n",
      "\n",
      "\n",
      "Distribution by Priority:\n",
      "+--------+-----+\n",
      "|priority|count|\n",
      "+--------+-----+\n",
      "|    High|  271|\n",
      "|     Low|  250|\n",
      "|  Medium|  249|\n",
      "|Critical|  230|\n",
      "+--------+-----+\n",
      "\n",
      "\n",
      "Average Resolution Time (hours) by Priority:\n",
      "+--------+---------------------+\n",
      "|priority|avg(resolution_hours)|\n",
      "+--------+---------------------+\n",
      "|Critical|    36.43157894736842|\n",
      "|    High|    36.67256637168141|\n",
      "|     Low|    35.84313725490196|\n",
      "|  Medium|   36.891891891891895|\n",
      "+--------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate and save data\n",
    "schema = define_schema()\n",
    "data = generate_sample_data(1000)\n",
    "df = save_data(spark, data, schema, \"../data/raw/support_tickets\")\n",
    "\n",
    "# Display a sample of the data\n",
    "print(\"Sample of generated tickets:\")\n",
    "df.show(5)\n",
    "\n",
    "# Show some basic statistics\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"Total Tickets: {df.count()}\")\n",
    "\n",
    "print(\"\\nDistribution by Category:\")\n",
    "df.groupBy(\"issue_category\").count().show()\n",
    "\n",
    "print(\"\\nDistribution by Priority:\")\n",
    "df.groupBy(\"priority\").count().show()\n",
    "\n",
    "print(\"\\nAverage Resolution Time (hours) by Priority:\")\n",
    "df.filter(df.resolution_date.isNotNull()) \\\n",
    "  .selectExpr(\"priority\", \"timestampdiff(HOUR, creation_date, resolution_date) as resolution_hours\") \\\n",
    "  .groupBy(\"priority\") \\\n",
    "  .avg(\"resolution_hours\") \\\n",
    "  .orderBy(\"priority\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b214bb9-e971-44a9-b8d8-e75053be0659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ETL pipeline...\n",
      "Extracting data...\n",
      "Transforming data...\n",
      "Loading processed data...\n",
      "ETL pipeline completed successfully!\n",
      "Sample of processed data:\n",
      "+-----------+----------+---------------+--------+-----------+--------------------+--------------------+------------------+--------------------+---------------------+-------------+------------+------------+-------------+------------------+------------+\n",
      "|customer_id| ticket_id| issue_category|priority|     status|       creation_date|     resolution_date|satisfaction_score|         description|resolution_time_hours|creation_hour|creation_day|  sla_status|total_tickets|  avg_satisfaction|sla_breaches|\n",
      "+-----------+----------+---------------+--------+-----------+--------------------+--------------------+------------------+--------------------+---------------------+-------------+------------+------------+-------------+------------------+------------+\n",
      "|   CUST-004|TICK-00250|        Storage|    High|  Escalated|2024-12-06 16:28:...|                NULL|              NULL|Customer reported...|                 NULL|           16|           6|Breached SLA|           17|               3.4|          16|\n",
      "|   CUST-012|TICK-00251|       Security|  Medium|  Escalated|2024-11-19 11:23:...|                NULL|              NULL|Customer reported...|                 NULL|           11|           3|Breached SLA|           11|              2.75|          10|\n",
      "|   CUST-043|TICK-00252|     Networking|    High|   Resolved|2024-12-02 04:04:...|2024-12-02 13:04:...|                 1|Customer reported...|                  9.0|            4|           2|Breached SLA|           11| 2.111111111111111|           8|\n",
      "|   CUST-055|TICK-00253|     Networking|     Low|In Progress|2024-11-30 06:16:...|                NULL|              NULL|Customer reported...|                 NULL|            6|           7|Breached SLA|           13|2.8333333333333335|          12|\n",
      "|   CUST-039|TICK-00254|       Database|  Medium|In Progress|2024-11-08 17:46:...|                NULL|              NULL|Customer reported...|                 NULL|           17|           6|Breached SLA|           11|               2.5|          11|\n",
      "|   CUST-060|TICK-00255|     Networking|  Medium|  Escalated|2024-11-13 14:38:...|                NULL|              NULL|Customer reported...|                 NULL|           14|           4|Breached SLA|            9|               1.5|           9|\n",
      "|   CUST-082|TICK-00256|        Storage|    High|     Closed|2024-11-28 04:08:...|2024-11-29 16:08:...|                 1|Customer reported...|                 36.0|            4|           5|Breached SLA|           12|2.8333333333333335|          11|\n",
      "|   CUST-079|TICK-00257|API Integration|  Medium|   Resolved|2024-12-01 06:05:...|2024-12-01 23:05:...|                 4|Customer reported...|                 17.0|            6|           1|  Within SLA|            8|2.8333333333333335|           7|\n",
      "|   CUST-092|TICK-00258|       Security|Critical|        New|2024-11-09 19:01:...|                NULL|              NULL|Customer reported...|                 NULL|           19|           7|Breached SLA|           10|               3.5|          10|\n",
      "|   CUST-017|TICK-00259|        Storage|     Low|        New|2024-11-14 09:17:...|                NULL|              NULL|Customer reported...|                 NULL|            9|           5|Breached SLA|           12|3.8333333333333335|           8|\n",
      "|   CUST-076|TICK-00260|       Security|     Low|        New|2024-11-28 06:27:...|                NULL|              NULL|Customer reported...|                 NULL|            6|           5|Breached SLA|            9|2.6666666666666665|           8|\n",
      "|   CUST-024|TICK-00261|API Integration|    High|   Resolved|2024-12-02 17:41:...|2024-12-03 11:41:...|                 1|Customer reported...|                 18.0|           17|           2|Breached SLA|           11|3.4285714285714284|           7|\n",
      "|   CUST-050|TICK-00262|   Login Issues|  Medium|  Escalated|2024-11-11 13:49:...|                NULL|              NULL|Customer reported...|                 NULL|           13|           2|Breached SLA|            9|               4.0|           9|\n",
      "|   CUST-006|TICK-00263|       Database|Critical|   Resolved|2024-11-26 18:05:...|2024-11-27 04:05:...|                 1|Customer reported...|                 10.0|           18|           3|Breached SLA|           12|               3.5|          11|\n",
      "|   CUST-060|TICK-00264|       Security|Critical|        New|2024-11-21 06:11:...|                NULL|              NULL|Customer reported...|                 NULL|            6|           5|Breached SLA|            9|               1.5|           9|\n",
      "|   CUST-080|TICK-00265|    Performance|Critical|        New|2024-11-20 14:24:...|                NULL|              NULL|Customer reported...|                 NULL|           14|           4|Breached SLA|           13|             2.625|          12|\n",
      "|   CUST-081|TICK-00266|        Storage|  Medium|  Escalated|2024-11-17 21:13:...|                NULL|              NULL|Customer reported...|                 NULL|           21|           1|Breached SLA|           11|             2.875|           9|\n",
      "|   CUST-054|TICK-00267|        Storage|Critical|     Closed|2024-11-27 23:20:...|2024-11-28 14:20:...|                 5|Customer reported...|                 15.0|           23|           4|Breached SLA|           12|               2.4|          12|\n",
      "|   CUST-052|TICK-00268|   Login Issues|  Medium|        New|2024-11-15 05:24:...|                NULL|              NULL|Customer reported...|                 NULL|            5|           6|Breached SLA|            9|3.3333333333333335|           9|\n",
      "|   CUST-003|TICK-00269|        Storage|  Medium|        New|2024-12-08 06:13:...|                NULL|              NULL|Customer reported...|                 NULL|            6|           1|Breached SLA|           11|              4.25|          10|\n",
      "+-----------+----------+---------------+--------+-----------+--------------------+--------------------+------------------+--------------------+---------------------+-------------+------------+------------+-------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "SLA Status Distribution:\n",
      "+--------+------------+-----+\n",
      "|priority|  sla_status|count|\n",
      "+--------+------------+-----+\n",
      "|Critical|Breached SLA|  222|\n",
      "|Critical|  Within SLA|    8|\n",
      "|    High|Breached SLA|  260|\n",
      "|    High|  Within SLA|   11|\n",
      "|     Low|Breached SLA|  180|\n",
      "|     Low|  Within SLA|   70|\n",
      "|  Medium|Breached SLA|  210|\n",
      "|  Medium|  Within SLA|   39|\n",
      "+--------+------------+-----+\n",
      "\n",
      "\n",
      "Customer Satisfaction by Category:\n",
      "+---------------+-----------------------+-----------------+\n",
      "| issue_category|avg(satisfaction_score)|sum(sla_breaches)|\n",
      "+---------------+-----------------------+-----------------+\n",
      "|       Security|     2.8703703703703702|             1055|\n",
      "|API Integration|     3.2222222222222223|             1330|\n",
      "|   Login Issues|      2.923076923076923|             1019|\n",
      "|     Networking|     2.8615384615384616|             1229|\n",
      "|        Storage|      3.056603773584906|             1229|\n",
      "|    Performance|      2.911111111111111|             1232|\n",
      "|       Database|     3.1372549019607843|             1257|\n",
      "|        Billing|      2.607843137254902|             1209|\n",
      "+---------------+-----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from etl_pipeline import SupportTicketETL\n",
    "\n",
    "# Initialize ETL\n",
    "etl = SupportTicketETL(spark)\n",
    "\n",
    "# Run pipeline\n",
    "processed_df = etl.run_pipeline(\n",
    "    input_path=\"../data/raw/support_tickets\",\n",
    "    output_path=\"../data/processed\"\n",
    ")\n",
    "\n",
    "# Show transformations\n",
    "print(\"Sample of processed data:\")\n",
    "processed_df.show()\n",
    "\n",
    "print(\"\\nSLA Status Distribution:\")\n",
    "processed_df.groupBy(\"priority\", \"sla_status\").count().orderBy(\"priority\", \"sla_status\").show()\n",
    "\n",
    "print(\"\\nCustomer Satisfaction by Category:\")\n",
    "processed_df.groupBy(\"issue_category\").agg({\n",
    "    \"satisfaction_score\": \"avg\",\n",
    "    \"sla_breaches\": \"sum\"\n",
    "}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34212318-7da7-4848-be3a-1b7bb9fc6473",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/style/core.py:137\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py:866\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    865\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 866\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_or_url(fname) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py:843\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    842\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[0;32m--> 843\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msupport_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupportAnalyzer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize analyzer\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m SupportAnalyzer(spark)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run analysis\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mrun_analysis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/processed_tickets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CSAnalytics/notebooks/../scripts/support_analysis.py:11\u001b[0m, in \u001b[0;36mSupportAnalyzer.__init__\u001b[0;34m(self, spark)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize analyzer with SparkSession\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark \u001b[38;5;241m=\u001b[39m spark\n\u001b[0;32m---> 11\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/style/core.py:139\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "from support_analysis import SupportAnalyzer\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = SupportAnalyzer(spark)\n",
    "\n",
    "# Run analysis\n",
    "df = analyzer.run_analysis(\"../data/processed/processed_tickets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847e266-1b6b-4f54-8083-eed0a32a5303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
